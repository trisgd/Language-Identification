{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Language Identification_ANN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmFRoP2LBNV2",
        "outputId": "25b5ed65-fcc5-475c-e977-c137ce6f53a8"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbO7LYf6Ds4H"
      },
      "source": [
        "#Using ANN \n",
        "\n",
        "\n",
        "*   Trained on 8 languages\n",
        "*   Before running download the sentences.csv from https://downloads.tatoeba.org/exports/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AX4koHlGwlO"
      },
      "source": [
        "#Importing the dataset\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/gdrive/My Drive/Data/sentences.csv',\n",
        "                            sep='\\t', \n",
        "                            encoding='utf8', \n",
        "                            index_col=0,\n",
        "                            names=['lang','text'])\n",
        "\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eR4yIcoNW6K"
      },
      "source": [
        "filt = [True if 40<=len(s)<=500 else False for s in df['text']]\n",
        "df = df[filt]\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuAZzStdQ-yb"
      },
      "source": [
        "# We will train this on only 8 languages - \n",
        "lang_filter = ['deu', 'eng', 'fra', 'ita', 'por', 'spa', 'ara', 'ben']\n",
        "\n",
        "def clean_data2(data,langlist):\n",
        "  data = data.loc[data['lang'].isin(langlist)]\n",
        "  return data\n",
        "\n",
        "df_new = clean_data2(df,lang_filter)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "8T351E_StmEn",
        "outputId": "4463198e-dccb-4c87-fecd-0f984423bc1b"
      },
      "source": [
        "df_new"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lang</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>deu</td>\n",
              "      <td>Heute ist der 18. Juni und das ist der Geburts...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>deu</td>\n",
              "      <td>Herzlichen Glückwunsch zum Geburtstag, Muiriel!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>deu</td>\n",
              "      <td>Ich weiß einfach nicht, was ich sagen soll.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>deu</td>\n",
              "      <td>Aus irgendeinem Grund hat das Mikrofon gerade ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>deu</td>\n",
              "      <td>Die Ausbildung in dieser Welt enttäuscht mich.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9779378</th>\n",
              "      <td>eng</td>\n",
              "      <td>There's nothing that can't be bought with money.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9779379</th>\n",
              "      <td>eng</td>\n",
              "      <td>I got up earlier than usual, so I could catch ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9779381</th>\n",
              "      <td>eng</td>\n",
              "      <td>People don't read novels as much as they used to.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9779392</th>\n",
              "      <td>por</td>\n",
              "      <td>Os garotos estavam completamente cobertos de l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9779393</th>\n",
              "      <td>por</td>\n",
              "      <td>Os meninos estavam completamente cobertos de l...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1408797 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        lang                                               text\n",
              "81       deu  Heute ist der 18. Juni und das ist der Geburts...\n",
              "82       deu    Herzlichen Glückwunsch zum Geburtstag, Muiriel!\n",
              "89       deu        Ich weiß einfach nicht, was ich sagen soll.\n",
              "94       deu  Aus irgendeinem Grund hat das Mikrofon gerade ...\n",
              "96       deu     Die Ausbildung in dieser Welt enttäuscht mich.\n",
              "...      ...                                                ...\n",
              "9779378  eng   There's nothing that can't be bought with money.\n",
              "9779379  eng  I got up earlier than usual, so I could catch ...\n",
              "9779381  eng  People don't read novels as much as they used to.\n",
              "9779392  por  Os garotos estavam completamente cobertos de l...\n",
              "9779393  por  Os meninos estavam completamente cobertos de l...\n",
              "\n",
              "[1408797 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjG4mgcZtnC2"
      },
      "source": [
        "#Trimming the dataset \n",
        "n = 10000\n",
        "df_red = df_new.groupby('lang').apply(lambda x: x.sample(min(n,len(x)))).reset_index(drop=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9JA7RFQu_I7"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test =  train_test_split(df_red, test_size=0.20, random_state=42)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbRFE9rhvAen"
      },
      "source": [
        "valid, test = train_test_split(test, test_size=0.7, random_state=30)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CmIQ1a3wZpd",
        "outputId": "0768eea1-398a-41f5-c671-43950ca18f9d"
      },
      "source": [
        "print(train.shape)\n",
        "print(valid.shape)\n",
        "print(test.shape)\n",
        "train.to_csv('/content/gdrive/My Drive/Data/train.csv')\n",
        "valid.to_csv('/content/gdrive/My Drive/Data/valid.csv')\n",
        "test.to_csv('/content/gdrive/My Drive/Data/test.csv')\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(51940, 2)\n",
            "(3895, 2)\n",
            "(9091, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9KBLaojxJVb",
        "outputId": "85c85b1f-7acf-4c49-f7c5-5630e234700a"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "def bigram(text,n_feat):\n",
        "    vectorizer = CountVectorizer(analyzer='char',\n",
        "                            ngram_range=(2,2),max_features=n_feat)\n",
        "    \n",
        "    X = vectorizer.fit_transform(text)\n",
        "    feature_names = vectorizer.get_feature_names()    \n",
        "    return feature_names\n",
        "\n",
        "features = {}\n",
        "features_set = set()\n",
        "\n",
        "for l in lang_filter:\n",
        "    corpus = train[train.lang==l]['text']\n",
        "    bigrams = bigram(corpus,250)\n",
        "    features[l] = bigrams\n",
        "    features_set.update(bigrams)\n",
        "    \n",
        "print(features_set)\n",
        "\n",
        "# Vocab created to feed into the Count Vectorizer for training data\n",
        "vocab = dict()\n",
        "for i,f in enumerate(features_set):\n",
        "    vocab[f]=i\n",
        "\n",
        "print(vocab)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{' t', 'عم', ' p', 'ro', 'بي', 'ُ ', 'ia', 'oi', 'ذي', \"u'\", 'tu', 'né', ' ر', 'mi', 'sn', 'اح', 'a?', 'ld', ' ন', 'se', 'fu', ' ل', ' à', 'op', 'ময', 'تق', ' e', 'াস', 'لع', 'কট', 'hé', 'سب', 'ct', ' c', 'wi', 'মধ', 'ly', ' ঘ', 'বা', 'لم', 'ই।', 'جم', 'in', 'e,', 'عد', 'তি', 'হল', \"'é\", ' ذ', ' ج', ' ص', 'لا', 'রো', 'হ ', 'ci', 'no', 'হয', 'ست', 'نس', 'tã', 'ত ', ' ح', 'y ', 's.', 'اه', 'دا', 'রি', 'rà', 'sc', 'a.', ' ফ', 'na', 'zu', 'ué', 'rt', 'াল', 've', 'قر', 'ep', 'ev', 'أو', 'اض', ' গ', 'পন', 'ب ', 'كي', 'za', ' ম', 'لر', 'hl', 'ام', 'kl', 'el', 'mu', 'lh', 'অপ', 'ম।', 'ol', 'ez', 'qu', 'تط', 'ذا', 'ó ', 'و ', 'ে ', 'েষ', 'o?', 'ze', 'হা', 'as', 'be', 'না', 'وي', 'az', 'ab', 'ap', 'اج', 'وا', 'ي.', 'ال', '\"i', 'এখ', 'দি', 'ea', \"e'\", 'াঁ', 'lu', 'ুগ', 'ّة', 'াত', 'বর', 'ن.', 'if', 'াদ', 'gr', 'স ', ' ق', '? ', 'ষা', ' b', 'gh', 'از', 'د ', 'ুম', 'lm', 'ن ', 'nk', 'u ', 'ju', 'eh', 'أخ', ' ش', '। ', 'sp', 'كا', 'عة', 'حي', ' উ', 'طي', 'ße', 'س ', ' ছ', 'n ', 'ex', ' q', 'جد', 'n.', 'ধ্', 'é ', 'ee', 'm.', 'ur', 'by', 'َ ', 'ma', 'يد', 'খন', 'fa', 'vi', 'ew', 'mo', 'wu', 'يق', ' س', 'ফর', 'قو', 'লা', 'াক', 'r.', 'াম', 'ف ', 'bl', 'জন', 'zt', \"'o\", 'nc', 'w ', '্য', 'ব্', 'ns', 'াপ', ' ল', 'حت', 'عل', 'ول', 'i?', 'بد', 'تل', 'িৎ', 'dé', 'li', 'رة', ' ধ', 'ات', 'ড়', ' ü', 'ds', 'uy', 'ac', 'pl', 'll', 'هذ', 'بر', 't,', 'do', 'শ্', 'ের', 'নো', 'su', 'িন', 'gi', ' \"', '় ', 'ল।', 't ', 'ত্', '. ', 'ো।', 'bb', 'oy', 'খু', 'añ', 'f ', 'ê ', '، ', 'rl', 'eç', 'مك', 'fe', 'am', 'উ ', 'bo', 'مل', 'ef', 'vo', 'ছু', 'িট', 'اب', 'ষ্', ' শ', 'av', 'os', 'on', 'اد', 'আর', 'েউ', 'েই', 'e ', 'أس', 'my', 'ás', 'ik', 'és', 'েক', 'lt', ' ا', 'মন', 'mã', 'ön', 'تك', 'ذل', 'ço', 'ار', 'r ', 'o.', 'রহ', 'ি।', 'রত', 'ুর', 'مة', 'চি', 'de', 'আম', 'থে', 'ته', 'p ', 'te', 'z ', 'تح', 'জি', 'া।', 'tá', 'بل', 'í ', 'জ্', 'تو', 'ان', 'ta', 'd.', 'উচ', 'লে', ' ব', ' a', 'bt', 'اي', ' m', 'ão', 'চ্', 'يس', 'ুন', 'ät', 'pu', 'e.', ' জ', 'ুল', 'ة ', 'لب', 'عا', 'io', 'té', 'sa', 'ig', 'je', ' ك', 'nt', 'ا.', 'ob', 'عن', ' ?', 'nd', 'প্', 'au', 'si', 'زي', 'سي', '.\"', 'ra', ' ه', 'টম', 'شي', 'ru', 'ai', 'kn', 's,', 'কথ', 'খা', 'x ', 'bu', 're', 'োম', 'لى', 'هو', 'dí', 'oa', ' r', 'è ', 'nn', 'üc', 'ت ', 'এক', 'েছ', 'so', \"'s\", 'يه', 'la', 'zz', 'وب', 'ছে', ', ', 'to', \"'u\", 'ك ', 'لد', 'ني', 'دو', 'ic', 'n,', 'اف', ' অ', ' য', 'ল ', ' স', 'me', 'rg', 'gg', 'اق', '্ধ', 'ul', 'it', 'با', 'sã', 'ch', 'ng', 'da', 'েন', 'ية', 'اك', 'ند', 'أي', 'á ', 'ري', 'لش', 'নু', 'cl', '-t', 'ux', 'hs', 'pe', 'কল', 'yo', 'we', 'id', 'بع', 'اس', 'لل', 'ha', 'ty', 'ré', 'mp', 'hw', 'وم', 'হব', 'يّ', \"c'\", 'ao', 'l.', 'স্', 'co', 'لت', 'iq', 'ga', 'ق ', 'ما', 'ed', 'حا', 'শে', 'en', 'ù ', 'কা', 'ss', 'rd', 'at', 'ov', 't-', 'ح ', 'يو', 'ét', 'هن', 'ون', 'বস', 'aq', 'gt', 'মর', 'gl', ' দ', 'ey', 'og', 'شر', 'لح', 'ón', 'hm', 'ট ', 'us', 'um', 'ে।', 'িক', 'ke', 'ib', ' غ', 'ন্', 'ু ', 'ny', 'মি', 'sé', 'ij', 'قا', 'ওয', 'st', ' ট', 'xi', 'লত', 'خر', 'نّ', 'ki', 'كن', 'تر', 'রব', 'بو', 'সে', 'br', 'اً', 'ls', 'ry', 'াও', 'ih', 'বি', 'তা', \"s'\", 'ue', 'eg', 'pp', 'bi', 'েশ', 't.', 'up', 'পে', 'du', ' o', 'ye', \"i'\", 'ل ', 'n?', 'সব', 'o,', ' h', 'sm', 'در', 'য়', 'এট', 'যে', 'gn', 'র ', 'êt', 'iu', 'اع', 'مس', 'أك', ' k', ' n', 'èr', 'াট', 'فر', 'ন।', 'সি', 'تع', 'ذه', 'rf', 'l ', 'বল', 'rá', 'a ', 'rb', 'قي', 'رب', 'çã', 'ه ', 'cê', 'rè', 'wa', 'أن', 'دة', 'ান', '্ঞ', 'oh', 'ائ', \"t'\", 'ض ', 'مي', 'üb', 'ri', 'ন ', 'كو', 'رف', 'i.', 'ি ', 'نف', 'ছা', 'مع', 'পা', 'تن', 'rh', ' خ', 'hö', 'mm', 'نت', 'eb', 'গে', \"n'\", 'াব', 'مو', 'uf', 'يب', 'má', 'dr', 'ah', 'm ', 'ud', 'ে?', 'nh', 'aj', 'نا', 'সা', 'رو', 'বে', 'ko', 'لف', 'نه', 'ভা', 'rs', 'إل', 'od', 'eu', 'rn', 'tr', 'তো', 'য ', ' é', 'él', 'জ ', 'et', 'hi', 'টি', 'দে', 'ió', 'م ', 'عي', 'lé', 'রছ', 'রে', 'kt', 'à ', 'অন', 'কি', 'াথ', 'ek', 'rí', 'ür', 'صا', 'ন?', 'ér', 'تي', 'ça', 'ff', 'rr', 'un', 'af', 'gu', 'তে', 'hu', ' y', 'ès', 'قت', 'يم', 'يك', 'im', 'mb', \"'t\", 'ই ', 'ঞা', 'মা', 'لذ', 'لج', 'or', 'pa', \"d'\", 'uv', ' j', 'শি', 'ys', 'ম্', \"'i\", ' ক', 'لي', 'g ', 'ন,', 'än', 'wo', 'عر', 'c ', 'lg', 'uc', ' s', 'لّ', 'h ', 'éc', ' ভ', 'েট', 'án', 'غي', 'ে,', 'ad', '্ব', ' প', 'كل', ' w', 'ge', 'েয', ' م', ' i', 'لق', 'سل', 'ين', '়ি', 'ce', 'ow', 'ির', 'is', 'ুব', 'é.', 'رج', 'ছি', 'em', 'إن', 'ix', 'টা', 'ঙ্', 'tt', 'of', 'তু', 'ês', 'িছ', 'ر ', 'আপ', 'le', 'কর', 'ec', 'g.', 'oo', 'এই', 'ي ', 'সু', 'চে', ' ত', 'ck', 'বো', 'nz', 'r,', 'ায', 'ম ', 'lo', 'iv', 'থা', 'ا ', ' চ', 's-', 'تم', 'ui', ' و', 'rz', 'iè', 'ño', 'ca', 's ', 'قد', 'he', 'ya', 'rc', 'فا', 'সম', 'لن', 'ها', 'y.', 'েত', 'ja', 'i,', 'ka', 'rü', 'سا', 'াগ', 'wh', 'في', 'ée', 'জা', 'di', 'اء', 'ém', 'hä', 'ni', '়া', 'িশ', 'িল', 'k ', 'يع', 'tà', 'পর', 'ár', 'va', 'pr', 'لة', 'নি', 'ós', 'যা', 'ার', 'hr', ' f', 'ht', ' ف', 'عت', 'لأ', 'ه.', ' ও', 'ء ', 'دي', 'িজ', 'ña', ' g', 'لس', 'il', 'tz', 'ò ', 'ör', 'hn', 'ছন', 'nç', ' د', 'ba', 'ut', '্র', 'لغ', 'fo', 'vr', 'مر', 'بة', 'fi', ' z', ' u', 'üh', 'cu', 'jo', 'ej', ' ب', ' ي', 'fr', 'دم', 'টু', '্ত', 'ug', 'قة', 'لو', ' র', 'রা', 'äh', 'ً ', '়ে', 'চা', 'ou', 'াড', 'oc', 'ak', 'd ', 'rò', 'tw', 'من', '্ট', 'nã', 'i ', 'كث', 'مت', ' أ', 'iù', 'ía', 'نو', 'খে', 'ì ', 'িত', 'ot', 'েল', 'া ', 'ণ ', 'go', ' থ', 'ّا', 'াই', 'ব ', 'ho', 'ua', 'rk', 'ى ', 'nf', 'ো ', 'লো', 'أم', 'zi', 'uo', 'ar', 'মে', 'িয', ' খ', 'গ্', 'es', 'ie', 'th', 'টে', 'kö', 'ne', \"'e\", ' এ', ' إ', 'ft', 'جا', 'cc', ' d', 'eo', 'ei', 'rm', 'يل', 'ép', 'sh', 'er', \"l'\", 'কো', 'تا', 'ts', 'e?', 'ع ', 'াজ', '্গ', 'ti', 'ir', 'ও ', 'েখ', '্ক', 'يا', 'لص', 'al', ' হ', 'ag', 'po', 'a,', 'هم', 'ور', 'ير', 'লি', ' ت', 'را', 'o ', 'ুক', '্ষ', 'কে', ' è', 'به', 'om', 'oe', 'ة.', 'لإ', \"j'\", 'vu', 'aç', 'لك', 'له', ' ن', 'cr', ' আ', 'an', 'ay', 'ok', 'োন', ' l', 'حد', 'ক ', 'lc', 'pi', 'নে', ' v', 'mé', 'র্', 'fü', 'وق', ' ع', 'iz', 'dn', 'يت', 'ّ ', 'ক্', \"'a\", 'nu', 'حق'}\n",
            "{' t': 0, 'عم': 1, ' p': 2, 'ro': 3, 'بي': 4, 'ُ ': 5, 'ia': 6, 'oi': 7, 'ذي': 8, \"u'\": 9, 'tu': 10, 'né': 11, ' ر': 12, 'mi': 13, 'sn': 14, 'اح': 15, 'a?': 16, 'ld': 17, ' ন': 18, 'se': 19, 'fu': 20, ' ل': 21, ' à': 22, 'op': 23, 'ময': 24, 'تق': 25, ' e': 26, 'াস': 27, 'لع': 28, 'কট': 29, 'hé': 30, 'سب': 31, 'ct': 32, ' c': 33, 'wi': 34, 'মধ': 35, 'ly': 36, ' ঘ': 37, 'বা': 38, 'لم': 39, 'ই।': 40, 'جم': 41, 'in': 42, 'e,': 43, 'عد': 44, 'তি': 45, 'হল': 46, \"'é\": 47, ' ذ': 48, ' ج': 49, ' ص': 50, 'لا': 51, 'রো': 52, 'হ ': 53, 'ci': 54, 'no': 55, 'হয': 56, 'ست': 57, 'نس': 58, 'tã': 59, 'ত ': 60, ' ح': 61, 'y ': 62, 's.': 63, 'اه': 64, 'دا': 65, 'রি': 66, 'rà': 67, 'sc': 68, 'a.': 69, ' ফ': 70, 'na': 71, 'zu': 72, 'ué': 73, 'rt': 74, 'াল': 75, 've': 76, 'قر': 77, 'ep': 78, 'ev': 79, 'أو': 80, 'اض': 81, ' গ': 82, 'পন': 83, 'ب ': 84, 'كي': 85, 'za': 86, ' ম': 87, 'لر': 88, 'hl': 89, 'ام': 90, 'kl': 91, 'el': 92, 'mu': 93, 'lh': 94, 'অপ': 95, 'ম।': 96, 'ol': 97, 'ez': 98, 'qu': 99, 'تط': 100, 'ذا': 101, 'ó ': 102, 'و ': 103, 'ে ': 104, 'েষ': 105, 'o?': 106, 'ze': 107, 'হা': 108, 'as': 109, 'be': 110, 'না': 111, 'وي': 112, 'az': 113, 'ab': 114, 'ap': 115, 'اج': 116, 'وا': 117, 'ي.': 118, 'ال': 119, '\"i': 120, 'এখ': 121, 'দি': 122, 'ea': 123, \"e'\": 124, 'াঁ': 125, 'lu': 126, 'ুগ': 127, 'ّة': 128, 'াত': 129, 'বর': 130, 'ن.': 131, 'if': 132, 'াদ': 133, 'gr': 134, 'স ': 135, ' ق': 136, '? ': 137, 'ষা': 138, ' b': 139, 'gh': 140, 'از': 141, 'د ': 142, 'ুম': 143, 'lm': 144, 'ن ': 145, 'nk': 146, 'u ': 147, 'ju': 148, 'eh': 149, 'أخ': 150, ' ش': 151, '। ': 152, 'sp': 153, 'كا': 154, 'عة': 155, 'حي': 156, ' উ': 157, 'طي': 158, 'ße': 159, 'س ': 160, ' ছ': 161, 'n ': 162, 'ex': 163, ' q': 164, 'جد': 165, 'n.': 166, 'ধ্': 167, 'é ': 168, 'ee': 169, 'm.': 170, 'ur': 171, 'by': 172, 'َ ': 173, 'ma': 174, 'يد': 175, 'খন': 176, 'fa': 177, 'vi': 178, 'ew': 179, 'mo': 180, 'wu': 181, 'يق': 182, ' س': 183, 'ফর': 184, 'قو': 185, 'লা': 186, 'াক': 187, 'r.': 188, 'াম': 189, 'ف ': 190, 'bl': 191, 'জন': 192, 'zt': 193, \"'o\": 194, 'nc': 195, 'w ': 196, '্য': 197, 'ব্': 198, 'ns': 199, 'াপ': 200, ' ল': 201, 'حت': 202, 'عل': 203, 'ول': 204, 'i?': 205, 'بد': 206, 'تل': 207, 'িৎ': 208, 'dé': 209, 'li': 210, 'رة': 211, ' ধ': 212, 'ات': 213, 'ড়': 214, ' ü': 215, 'ds': 216, 'uy': 217, 'ac': 218, 'pl': 219, 'll': 220, 'هذ': 221, 'بر': 222, 't,': 223, 'do': 224, 'শ্': 225, 'ের': 226, 'নো': 227, 'su': 228, 'িন': 229, 'gi': 230, ' \"': 231, '় ': 232, 'ল।': 233, 't ': 234, 'ত্': 235, '. ': 236, 'ো।': 237, 'bb': 238, 'oy': 239, 'খু': 240, 'añ': 241, 'f ': 242, 'ê ': 243, '، ': 244, 'rl': 245, 'eç': 246, 'مك': 247, 'fe': 248, 'am': 249, 'উ ': 250, 'bo': 251, 'مل': 252, 'ef': 253, 'vo': 254, 'ছু': 255, 'িট': 256, 'اب': 257, 'ষ্': 258, ' শ': 259, 'av': 260, 'os': 261, 'on': 262, 'اد': 263, 'আর': 264, 'েউ': 265, 'েই': 266, 'e ': 267, 'أس': 268, 'my': 269, 'ás': 270, 'ik': 271, 'és': 272, 'েক': 273, 'lt': 274, ' ا': 275, 'মন': 276, 'mã': 277, 'ön': 278, 'تك': 279, 'ذل': 280, 'ço': 281, 'ار': 282, 'r ': 283, 'o.': 284, 'রহ': 285, 'ি।': 286, 'রত': 287, 'ুর': 288, 'مة': 289, 'চি': 290, 'de': 291, 'আম': 292, 'থে': 293, 'ته': 294, 'p ': 295, 'te': 296, 'z ': 297, 'تح': 298, 'জি': 299, 'া।': 300, 'tá': 301, 'بل': 302, 'í ': 303, 'জ্': 304, 'تو': 305, 'ان': 306, 'ta': 307, 'd.': 308, 'উচ': 309, 'লে': 310, ' ব': 311, ' a': 312, 'bt': 313, 'اي': 314, ' m': 315, 'ão': 316, 'চ্': 317, 'يس': 318, 'ুন': 319, 'ät': 320, 'pu': 321, 'e.': 322, ' জ': 323, 'ুল': 324, 'ة ': 325, 'لب': 326, 'عا': 327, 'io': 328, 'té': 329, 'sa': 330, 'ig': 331, 'je': 332, ' ك': 333, 'nt': 334, 'ا.': 335, 'ob': 336, 'عن': 337, ' ?': 338, 'nd': 339, 'প্': 340, 'au': 341, 'si': 342, 'زي': 343, 'سي': 344, '.\"': 345, 'ra': 346, ' ه': 347, 'টম': 348, 'شي': 349, 'ru': 350, 'ai': 351, 'kn': 352, 's,': 353, 'কথ': 354, 'খা': 355, 'x ': 356, 'bu': 357, 're': 358, 'োম': 359, 'لى': 360, 'هو': 361, 'dí': 362, 'oa': 363, ' r': 364, 'è ': 365, 'nn': 366, 'üc': 367, 'ت ': 368, 'এক': 369, 'েছ': 370, 'so': 371, \"'s\": 372, 'يه': 373, 'la': 374, 'zz': 375, 'وب': 376, 'ছে': 377, ', ': 378, 'to': 379, \"'u\": 380, 'ك ': 381, 'لد': 382, 'ني': 383, 'دو': 384, 'ic': 385, 'n,': 386, 'اف': 387, ' অ': 388, ' য': 389, 'ল ': 390, ' স': 391, 'me': 392, 'rg': 393, 'gg': 394, 'اق': 395, '্ধ': 396, 'ul': 397, 'it': 398, 'با': 399, 'sã': 400, 'ch': 401, 'ng': 402, 'da': 403, 'েন': 404, 'ية': 405, 'اك': 406, 'ند': 407, 'أي': 408, 'á ': 409, 'ري': 410, 'لش': 411, 'নু': 412, 'cl': 413, '-t': 414, 'ux': 415, 'hs': 416, 'pe': 417, 'কল': 418, 'yo': 419, 'we': 420, 'id': 421, 'بع': 422, 'اس': 423, 'لل': 424, 'ha': 425, 'ty': 426, 'ré': 427, 'mp': 428, 'hw': 429, 'وم': 430, 'হব': 431, 'يّ': 432, \"c'\": 433, 'ao': 434, 'l.': 435, 'স্': 436, 'co': 437, 'لت': 438, 'iq': 439, 'ga': 440, 'ق ': 441, 'ما': 442, 'ed': 443, 'حا': 444, 'শে': 445, 'en': 446, 'ù ': 447, 'কা': 448, 'ss': 449, 'rd': 450, 'at': 451, 'ov': 452, 't-': 453, 'ح ': 454, 'يو': 455, 'ét': 456, 'هن': 457, 'ون': 458, 'বস': 459, 'aq': 460, 'gt': 461, 'মর': 462, 'gl': 463, ' দ': 464, 'ey': 465, 'og': 466, 'شر': 467, 'لح': 468, 'ón': 469, 'hm': 470, 'ট ': 471, 'us': 472, 'um': 473, 'ে।': 474, 'িক': 475, 'ke': 476, 'ib': 477, ' غ': 478, 'ন্': 479, 'ু ': 480, 'ny': 481, 'মি': 482, 'sé': 483, 'ij': 484, 'قا': 485, 'ওয': 486, 'st': 487, ' ট': 488, 'xi': 489, 'লত': 490, 'خر': 491, 'نّ': 492, 'ki': 493, 'كن': 494, 'تر': 495, 'রব': 496, 'بو': 497, 'সে': 498, 'br': 499, 'اً': 500, 'ls': 501, 'ry': 502, 'াও': 503, 'ih': 504, 'বি': 505, 'তা': 506, \"s'\": 507, 'ue': 508, 'eg': 509, 'pp': 510, 'bi': 511, 'েশ': 512, 't.': 513, 'up': 514, 'পে': 515, 'du': 516, ' o': 517, 'ye': 518, \"i'\": 519, 'ل ': 520, 'n?': 521, 'সব': 522, 'o,': 523, ' h': 524, 'sm': 525, 'در': 526, 'য়': 527, 'এট': 528, 'যে': 529, 'gn': 530, 'র ': 531, 'êt': 532, 'iu': 533, 'اع': 534, 'مس': 535, 'أك': 536, ' k': 537, ' n': 538, 'èr': 539, 'াট': 540, 'فر': 541, 'ন।': 542, 'সি': 543, 'تع': 544, 'ذه': 545, 'rf': 546, 'l ': 547, 'বল': 548, 'rá': 549, 'a ': 550, 'rb': 551, 'قي': 552, 'رب': 553, 'çã': 554, 'ه ': 555, 'cê': 556, 'rè': 557, 'wa': 558, 'أن': 559, 'دة': 560, 'ান': 561, '্ঞ': 562, 'oh': 563, 'ائ': 564, \"t'\": 565, 'ض ': 566, 'مي': 567, 'üb': 568, 'ri': 569, 'ন ': 570, 'كو': 571, 'رف': 572, 'i.': 573, 'ি ': 574, 'نف': 575, 'ছা': 576, 'مع': 577, 'পা': 578, 'تن': 579, 'rh': 580, ' خ': 581, 'hö': 582, 'mm': 583, 'نت': 584, 'eb': 585, 'গে': 586, \"n'\": 587, 'াব': 588, 'مو': 589, 'uf': 590, 'يب': 591, 'má': 592, 'dr': 593, 'ah': 594, 'm ': 595, 'ud': 596, 'ে?': 597, 'nh': 598, 'aj': 599, 'نا': 600, 'সা': 601, 'رو': 602, 'বে': 603, 'ko': 604, 'لف': 605, 'نه': 606, 'ভা': 607, 'rs': 608, 'إل': 609, 'od': 610, 'eu': 611, 'rn': 612, 'tr': 613, 'তো': 614, 'য ': 615, ' é': 616, 'él': 617, 'জ ': 618, 'et': 619, 'hi': 620, 'টি': 621, 'দে': 622, 'ió': 623, 'م ': 624, 'عي': 625, 'lé': 626, 'রছ': 627, 'রে': 628, 'kt': 629, 'à ': 630, 'অন': 631, 'কি': 632, 'াথ': 633, 'ek': 634, 'rí': 635, 'ür': 636, 'صا': 637, 'ন?': 638, 'ér': 639, 'تي': 640, 'ça': 641, 'ff': 642, 'rr': 643, 'un': 644, 'af': 645, 'gu': 646, 'তে': 647, 'hu': 648, ' y': 649, 'ès': 650, 'قت': 651, 'يم': 652, 'يك': 653, 'im': 654, 'mb': 655, \"'t\": 656, 'ই ': 657, 'ঞা': 658, 'মা': 659, 'لذ': 660, 'لج': 661, 'or': 662, 'pa': 663, \"d'\": 664, 'uv': 665, ' j': 666, 'শি': 667, 'ys': 668, 'ম্': 669, \"'i\": 670, ' ক': 671, 'لي': 672, 'g ': 673, 'ন,': 674, 'än': 675, 'wo': 676, 'عر': 677, 'c ': 678, 'lg': 679, 'uc': 680, ' s': 681, 'لّ': 682, 'h ': 683, 'éc': 684, ' ভ': 685, 'েট': 686, 'án': 687, 'غي': 688, 'ে,': 689, 'ad': 690, '্ব': 691, ' প': 692, 'كل': 693, ' w': 694, 'ge': 695, 'েয': 696, ' م': 697, ' i': 698, 'لق': 699, 'سل': 700, 'ين': 701, '়ি': 702, 'ce': 703, 'ow': 704, 'ির': 705, 'is': 706, 'ুব': 707, 'é.': 708, 'رج': 709, 'ছি': 710, 'em': 711, 'إن': 712, 'ix': 713, 'টা': 714, 'ঙ্': 715, 'tt': 716, 'of': 717, 'তু': 718, 'ês': 719, 'িছ': 720, 'ر ': 721, 'আপ': 722, 'le': 723, 'কর': 724, 'ec': 725, 'g.': 726, 'oo': 727, 'এই': 728, 'ي ': 729, 'সু': 730, 'চে': 731, ' ত': 732, 'ck': 733, 'বো': 734, 'nz': 735, 'r,': 736, 'ায': 737, 'ম ': 738, 'lo': 739, 'iv': 740, 'থা': 741, 'ا ': 742, ' চ': 743, 's-': 744, 'تم': 745, 'ui': 746, ' و': 747, 'rz': 748, 'iè': 749, 'ño': 750, 'ca': 751, 's ': 752, 'قد': 753, 'he': 754, 'ya': 755, 'rc': 756, 'فا': 757, 'সম': 758, 'لن': 759, 'ها': 760, 'y.': 761, 'েত': 762, 'ja': 763, 'i,': 764, 'ka': 765, 'rü': 766, 'سا': 767, 'াগ': 768, 'wh': 769, 'في': 770, 'ée': 771, 'জা': 772, 'di': 773, 'اء': 774, 'ém': 775, 'hä': 776, 'ni': 777, '়া': 778, 'িশ': 779, 'িল': 780, 'k ': 781, 'يع': 782, 'tà': 783, 'পর': 784, 'ár': 785, 'va': 786, 'pr': 787, 'لة': 788, 'নি': 789, 'ós': 790, 'যা': 791, 'ার': 792, 'hr': 793, ' f': 794, 'ht': 795, ' ف': 796, 'عت': 797, 'لأ': 798, 'ه.': 799, ' ও': 800, 'ء ': 801, 'دي': 802, 'িজ': 803, 'ña': 804, ' g': 805, 'لس': 806, 'il': 807, 'tz': 808, 'ò ': 809, 'ör': 810, 'hn': 811, 'ছন': 812, 'nç': 813, ' د': 814, 'ba': 815, 'ut': 816, '্র': 817, 'لغ': 818, 'fo': 819, 'vr': 820, 'مر': 821, 'بة': 822, 'fi': 823, ' z': 824, ' u': 825, 'üh': 826, 'cu': 827, 'jo': 828, 'ej': 829, ' ب': 830, ' ي': 831, 'fr': 832, 'دم': 833, 'টু': 834, '্ত': 835, 'ug': 836, 'قة': 837, 'لو': 838, ' র': 839, 'রা': 840, 'äh': 841, 'ً ': 842, '়ে': 843, 'চা': 844, 'ou': 845, 'াড': 846, 'oc': 847, 'ak': 848, 'd ': 849, 'rò': 850, 'tw': 851, 'من': 852, '্ট': 853, 'nã': 854, 'i ': 855, 'كث': 856, 'مت': 857, ' أ': 858, 'iù': 859, 'ía': 860, 'نو': 861, 'খে': 862, 'ì ': 863, 'িত': 864, 'ot': 865, 'েল': 866, 'া ': 867, 'ণ ': 868, 'go': 869, ' থ': 870, 'ّا': 871, 'াই': 872, 'ব ': 873, 'ho': 874, 'ua': 875, 'rk': 876, 'ى ': 877, 'nf': 878, 'ো ': 879, 'লো': 880, 'أم': 881, 'zi': 882, 'uo': 883, 'ar': 884, 'মে': 885, 'িয': 886, ' খ': 887, 'গ্': 888, 'es': 889, 'ie': 890, 'th': 891, 'টে': 892, 'kö': 893, 'ne': 894, \"'e\": 895, ' এ': 896, ' إ': 897, 'ft': 898, 'جا': 899, 'cc': 900, ' d': 901, 'eo': 902, 'ei': 903, 'rm': 904, 'يل': 905, 'ép': 906, 'sh': 907, 'er': 908, \"l'\": 909, 'কো': 910, 'تا': 911, 'ts': 912, 'e?': 913, 'ع ': 914, 'াজ': 915, '্গ': 916, 'ti': 917, 'ir': 918, 'ও ': 919, 'েখ': 920, '্ক': 921, 'يا': 922, 'لص': 923, 'al': 924, ' হ': 925, 'ag': 926, 'po': 927, 'a,': 928, 'هم': 929, 'ور': 930, 'ير': 931, 'লি': 932, ' ت': 933, 'را': 934, 'o ': 935, 'ুক': 936, '্ষ': 937, 'কে': 938, ' è': 939, 'به': 940, 'om': 941, 'oe': 942, 'ة.': 943, 'لإ': 944, \"j'\": 945, 'vu': 946, 'aç': 947, 'لك': 948, 'له': 949, ' ن': 950, 'cr': 951, ' আ': 952, 'an': 953, 'ay': 954, 'ok': 955, 'োন': 956, ' l': 957, 'حد': 958, 'ক ': 959, 'lc': 960, 'pi': 961, 'নে': 962, ' v': 963, 'mé': 964, 'র্': 965, 'fü': 966, 'وق': 967, ' ع': 968, 'iz': 969, 'dn': 970, 'يت': 971, 'ّ ': 972, 'ক্': 973, \"'a\": 974, 'nu': 975, 'حق': 976}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhbbRJrn1q3L"
      },
      "source": [
        "vectorizer = CountVectorizer(analyzer='char',\n",
        "                             ngram_range=(2, 2),\n",
        "                            vocabulary=vocab)\n",
        "\n",
        "data_x = train['text']   \n",
        "X = vectorizer.fit_transform(data_x)\n",
        "feature_names = vectorizer.get_feature_names()\n",
        "\n",
        "train_features = pd.DataFrame(data=X.toarray(),columns=feature_names)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "poET0E1F348P",
        "outputId": "385e2ba0-97bf-4c95-aafb-bd014efd4d52"
      },
      "source": [
        "print(train_features)\n",
        "'''\n",
        "The columns in train_feat tells you about list of bigrams and the rows represent the sentences \n",
        "The zeros and ones indicate the presence or absence of the particular bigram in the sentence\n",
        "'''"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        t  عم   p  ro  بي  ُ   ia  oi  ذي  ...   ع  iz  dn  يت  ّ   ক্  'a  nu  حق\n",
            "0       0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "1       0   0   2   0   0   0   0   1   0  ...   0   0   0   0   0   0   1   0   0\n",
            "2       0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "3       1   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "4       1   0   1   1   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "...    ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..  ..  ..  ..\n",
            "51935   0   0   0   1   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "51936   0   0   0   0   0   0   1   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "51937   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   1   0   0   0   0\n",
            "51938   2   0   1   1   0   0   0   1   0  ...   0   0   0   0   0   0   0   0   0\n",
            "51939   0   0   1   1   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "\n",
            "[51940 rows x 977 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nThe columns in train_feat tells you about list of bigrams and the rows represent the sentences \\nThe zeros and ones indicate the presence or absence of the particular bigram in the sentence\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "OSPVhhzN3-U1",
        "outputId": "77042d79-abf1-449a-d941-d5ed82bb06a6"
      },
      "source": [
        "def normalized(train_features, feat):\n",
        "  tr_min = train_features.min()\n",
        "  tr_max = train_features.max()\n",
        "  feat = (feat - tr_min)/(tr_max-tr_min)\n",
        "  return feat\n",
        "\n",
        "train_features_norm = normalized(train_features,train_features)\n",
        "\n",
        "#Add target variable \n",
        "train_features_norm['lang_target'] = list(train['lang'])\n",
        "\n",
        "train_features_norm"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>t</th>\n",
              "      <th>عم</th>\n",
              "      <th>p</th>\n",
              "      <th>ro</th>\n",
              "      <th>بي</th>\n",
              "      <th>ُ</th>\n",
              "      <th>ia</th>\n",
              "      <th>oi</th>\n",
              "      <th>ذي</th>\n",
              "      <th>u'</th>\n",
              "      <th>tu</th>\n",
              "      <th>né</th>\n",
              "      <th>ر</th>\n",
              "      <th>mi</th>\n",
              "      <th>sn</th>\n",
              "      <th>اح</th>\n",
              "      <th>a?</th>\n",
              "      <th>ld</th>\n",
              "      <th>ন</th>\n",
              "      <th>se</th>\n",
              "      <th>fu</th>\n",
              "      <th>ل</th>\n",
              "      <th>à</th>\n",
              "      <th>op</th>\n",
              "      <th>ময</th>\n",
              "      <th>تق</th>\n",
              "      <th>e</th>\n",
              "      <th>াস</th>\n",
              "      <th>لع</th>\n",
              "      <th>কট</th>\n",
              "      <th>hé</th>\n",
              "      <th>سب</th>\n",
              "      <th>ct</th>\n",
              "      <th>c</th>\n",
              "      <th>wi</th>\n",
              "      <th>মধ</th>\n",
              "      <th>ly</th>\n",
              "      <th>ঘ</th>\n",
              "      <th>বা</th>\n",
              "      <th>لم</th>\n",
              "      <th>...</th>\n",
              "      <th>কে</th>\n",
              "      <th>è</th>\n",
              "      <th>به</th>\n",
              "      <th>om</th>\n",
              "      <th>oe</th>\n",
              "      <th>ة.</th>\n",
              "      <th>لإ</th>\n",
              "      <th>j'</th>\n",
              "      <th>vu</th>\n",
              "      <th>aç</th>\n",
              "      <th>لك</th>\n",
              "      <th>له</th>\n",
              "      <th>ن</th>\n",
              "      <th>cr</th>\n",
              "      <th>আ</th>\n",
              "      <th>an</th>\n",
              "      <th>ay</th>\n",
              "      <th>ok</th>\n",
              "      <th>োন</th>\n",
              "      <th>l</th>\n",
              "      <th>حد</th>\n",
              "      <th>ক</th>\n",
              "      <th>lc</th>\n",
              "      <th>pi</th>\n",
              "      <th>নে</th>\n",
              "      <th>v</th>\n",
              "      <th>mé</th>\n",
              "      <th>র্</th>\n",
              "      <th>fü</th>\n",
              "      <th>وق</th>\n",
              "      <th>ع</th>\n",
              "      <th>iz</th>\n",
              "      <th>dn</th>\n",
              "      <th>يت</th>\n",
              "      <th>ّ</th>\n",
              "      <th>ক্</th>\n",
              "      <th>'a</th>\n",
              "      <th>nu</th>\n",
              "      <th>حق</th>\n",
              "      <th>lang_target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.153846</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>ita</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>fra</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.153846</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>spa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>deu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.153846</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>fra</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51935</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>spa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51936</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>ita</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51937</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>ara</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51938</th>\n",
              "      <td>0.153846</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>eng</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51939</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>spa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>51940 rows × 978 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              t   عم         p     ro   بي  ...   ক্    'a   nu   حق  lang_target\n",
              "0      0.000000  0.0  0.000000  0.000  0.0  ...  0.0  0.00  0.0  0.0          ita\n",
              "1      0.000000  0.0  0.071429  0.000  0.0  ...  0.0  0.25  0.0  0.0          fra\n",
              "2      0.000000  0.0  0.000000  0.000  0.0  ...  0.0  0.00  0.0  0.0          spa\n",
              "3      0.076923  0.0  0.000000  0.000  0.0  ...  0.0  0.00  0.0  0.0          deu\n",
              "4      0.076923  0.0  0.035714  0.125  0.0  ...  0.0  0.00  0.0  0.0          fra\n",
              "...         ...  ...       ...    ...  ...  ...  ...   ...  ...  ...          ...\n",
              "51935  0.000000  0.0  0.000000  0.125  0.0  ...  0.0  0.00  0.0  0.0          spa\n",
              "51936  0.000000  0.0  0.000000  0.000  0.0  ...  0.0  0.00  0.0  0.0          ita\n",
              "51937  0.000000  0.0  0.000000  0.000  0.0  ...  0.0  0.00  0.0  0.0          ara\n",
              "51938  0.153846  0.0  0.035714  0.125  0.0  ...  0.0  0.00  0.0  0.0          eng\n",
              "51939  0.000000  0.0  0.035714  0.125  0.0  ...  0.0  0.00  0.0  0.0          spa\n",
              "\n",
              "[51940 rows x 978 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_5YMKFa956A"
      },
      "source": [
        "# Data Processing for the test and validation set\n",
        "\n",
        "valid_text = valid['text']   \n",
        "X = vectorizer.fit_transform(valid_text)\n",
        "\n",
        "valid_features = pd.DataFrame(data=X.toarray(),columns=feature_names)\n",
        "valid_features = normalized(train_features,valid_features)\n",
        "valid_features['lang_target'] = list(valid['lang'])\n",
        "\n",
        "\n",
        "test_text = test['text']   \n",
        "X = vectorizer.fit_transform(test_text)\n",
        "\n",
        "test_features = pd.DataFrame(data=X.toarray(),columns=feature_names)\n",
        "test_features = normalized(train_features, test_features)\n",
        "test_features['lang'] = list(test['lang'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBGVBEGoA9MF",
        "outputId": "1003370c-36d9-479f-aa36-81bdc91bb194"
      },
      "source": [
        "print(test_features.shape)\n",
        "print(valid_features.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9091, 978)\n",
            "(3895, 978)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6xF7a9lCN8d",
        "outputId": "663c6d36-043e-4abe-f49e-16c58cba032b"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "\n",
        "lang_filter = ['deu', 'eng', 'fra', 'ita', 'por', 'spa', 'ara', 'ben']\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(lang_filter)\n",
        "\n",
        "X_train = train_features_norm.drop('lang_target',axis = 1)\n",
        "Y_train = np_utils.to_categorical(encoder.transform(train_features_norm['lang_target']))\n",
        "\n",
        "X_val = valid_features.drop('lang_target',axis = 1)\n",
        "Y_val = np_utils.to_categorical(encoder.transform(valid_features['lang_target']))\n",
        "\n",
        "X_test = test_features.drop('lang',axis = 1)\n",
        "Y_test = np_utils.to_categorical(encoder.transform(test_features['lang']))\n",
        "\n",
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_val.shape,Y_val.shape)\n",
        "print(X_test.shape,Y_test.shape)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(51940, 977) (51940, 8)\n",
            "(3895, 977) (3895, 8)\n",
            "(9091, 977) (9091, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2N-PYRav0B5",
        "outputId": "29d097bd-adf2-4fb9-be5f-eb4b919d5959"
      },
      "source": [
        "input_dim = X_train.shape[1]\n",
        "print('Input Dim into Layer : ',input_dim)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Dim into Layer :  977\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXcFnc2peYYT",
        "outputId": "ef1cfcb7-1653-4ea8-a003-37d5a33520b4"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
        "import keras\n",
        "\n",
        "def fit_model(input_dim ,nodes,epochs,batch_size):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(nodes[0], input_dim=input_dim, activation='relu'))\n",
        "    model.add(Dense(nodes[1], activation='relu'))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(nodes[2], activation='relu'))\n",
        "    model.add(Dense(8, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size)\n",
        "    \n",
        "    train_acc = model.evaluate(X_train, Y_train)\n",
        "    val_acc = model.evaluate(X_val, Y_val)\n",
        "    \n",
        "    return round(train_acc[1]*100,2),round(val_acc[1]*100,2)\n",
        "\n",
        "nodes = [[100,100,50],[200,200,100],[300,200,100],[500,500,250]]\n",
        "epochs = [1,2,3,4]\n",
        "batch_size = [10,100,1000]\n",
        "\n",
        "results = []\n",
        "i = 0\n",
        "\n",
        "for n in nodes:\n",
        "    print(\"MODEL: \", i)\n",
        "    for e in epochs:\n",
        "        for b in batch_size:\n",
        "            result = {}\n",
        "            \n",
        "            result['model'] = i\n",
        "            result['nodes'] = n\n",
        "            result['epochs'] = e\n",
        "            result['batch_size'] = b\n",
        "            result['train'], result['valid'] = fit_model(input_dim,n,e,b)\n",
        "            \n",
        "            results.append(result)\n",
        "            i+= 1\n",
        "\n",
        "results_final = pd.DataFrame(results)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MODEL:  0\n",
            "5194/5194 [==============================] - 10s 2ms/step - loss: 0.2232 - accuracy: 0.9283\n",
            "1624/1624 [==============================] - 2s 1ms/step - loss: 0.0181 - accuracy: 0.9941\n",
            "122/122 [==============================] - 0s 1ms/step - loss: 0.0311 - accuracy: 0.9910\n",
            "520/520 [==============================] - 2s 3ms/step - loss: 0.6052 - accuracy: 0.8465\n",
            "1624/1624 [==============================] - 2s 1ms/step - loss: 0.0211 - accuracy: 0.9930\n",
            "122/122 [==============================] - 0s 1ms/step - loss: 0.0349 - accuracy: 0.9877\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 1.7708 - accuracy: 0.5519\n",
            "1624/1624 [==============================] - 2s 1ms/step - loss: 0.2478 - accuracy: 0.9665\n",
            "122/122 [==============================] - 0s 1ms/step - loss: 0.2518 - accuracy: 0.9630\n",
            "Epoch 1/2\n",
            "5194/5194 [==============================] - 9s 2ms/step - loss: 0.2101 - accuracy: 0.9356\n",
            "Epoch 2/2\n",
            "5194/5194 [==============================] - 9s 2ms/step - loss: 0.0227 - accuracy: 0.9925\n",
            "1624/1624 [==============================] - 2s 1ms/step - loss: 0.0099 - accuracy: 0.9968\n",
            "122/122 [==============================] - 0s 1ms/step - loss: 0.0243 - accuracy: 0.9913\n",
            "Epoch 1/2\n",
            "520/520 [==============================] - 2s 3ms/step - loss: 0.6284 - accuracy: 0.8361\n",
            "Epoch 2/2\n",
            "520/520 [==============================] - 2s 3ms/step - loss: 0.0212 - accuracy: 0.9932\n",
            "1624/1624 [==============================] - 2s 1ms/step - loss: 0.0123 - accuracy: 0.9962\n",
            "122/122 [==============================] - 0s 1ms/step - loss: 0.0243 - accuracy: 0.9918\n",
            "Epoch 1/2\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 1.7133 - accuracy: 0.5044\n",
            "Epoch 2/2\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.1630 - accuracy: 0.9647\n",
            "1624/1624 [==============================] - 2s 1ms/step - loss: 0.0556 - accuracy: 0.9843\n",
            "122/122 [==============================] - 0s 1ms/step - loss: 0.0617 - accuracy: 0.9787\n",
            "Epoch 1/3\n",
            "5194/5194 [==============================] - 9s 2ms/step - loss: 0.2186 - accuracy: 0.9244\n",
            "Epoch 2/3\n",
            "5194/5194 [==============================] - 9s 2ms/step - loss: 0.0199 - accuracy: 0.9933\n",
            "Epoch 3/3\n",
            "5194/5194 [==============================] - 9s 2ms/step - loss: 0.0134 - accuracy: 0.9955\n",
            "1624/1624 [==============================] - 2s 1ms/step - loss: 0.0072 - accuracy: 0.9978\n",
            "122/122 [==============================] - 0s 1ms/step - loss: 0.0230 - accuracy: 0.9923\n",
            "Epoch 1/3\n",
            "520/520 [==============================] - 2s 3ms/step - loss: 0.6180 - accuracy: 0.8169\n",
            "Epoch 2/3\n",
            "520/520 [==============================] - 2s 3ms/step - loss: 0.0213 - accuracy: 0.9933\n",
            "Epoch 3/3\n",
            "520/520 [==============================] - 2s 3ms/step - loss: 0.0158 - accuracy: 0.9946\n",
            "1624/1624 [==============================] - 2s 1ms/step - loss: 0.0083 - accuracy: 0.9976\n",
            "122/122 [==============================] - 0s 1ms/step - loss: 0.0244 - accuracy: 0.9915\n",
            "Epoch 1/3\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 1.7054 - accuracy: 0.5298\n",
            "Epoch 2/3\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.1293 - accuracy: 0.9722\n",
            "Epoch 3/3\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0424 - accuracy: 0.9886\n",
            "1624/1624 [==============================] - 2s 1ms/step - loss: 0.0254 - accuracy: 0.9936\n",
            "122/122 [==============================] - 0s 1ms/step - loss: 0.0350 - accuracy: 0.9882\n",
            "Epoch 1/4\n",
            "5194/5194 [==============================] - 9s 2ms/step - loss: 0.2280 - accuracy: 0.9231\n",
            "Epoch 2/4\n",
            "5194/5194 [==============================] - 9s 2ms/step - loss: 0.0197 - accuracy: 0.9940\n",
            "Epoch 3/4\n",
            "5194/5194 [==============================] - 9s 2ms/step - loss: 0.0130 - accuracy: 0.9959\n",
            "Epoch 4/4\n",
            "5194/5194 [==============================] - 9s 2ms/step - loss: 0.0104 - accuracy: 0.9967\n",
            "1624/1624 [==============================] - 2s 1ms/step - loss: 0.0056 - accuracy: 0.9981\n",
            "122/122 [==============================] - 0s 1ms/step - loss: 0.0363 - accuracy: 0.9902\n",
            "Epoch 1/4\n",
            "520/520 [==============================] - 2s 3ms/step - loss: 0.5982 - accuracy: 0.8194\n",
            "Epoch 2/4\n",
            "520/520 [==============================] - 2s 3ms/step - loss: 0.0194 - accuracy: 0.9945\n",
            "Epoch 3/4\n",
            "520/520 [==============================] - 2s 3ms/step - loss: 0.0134 - accuracy: 0.9957\n",
            "Epoch 4/4\n",
            "520/520 [==============================] - 2s 3ms/step - loss: 0.0100 - accuracy: 0.9968\n",
            "1624/1624 [==============================] - 2s 1ms/step - loss: 0.0111 - accuracy: 0.9963\n",
            "122/122 [==============================] - 0s 1ms/step - loss: 0.0313 - accuracy: 0.9905\n",
            "Epoch 1/4\n",
            "52/52 [==============================] - 2s 15ms/step - loss: 1.7459 - accuracy: 0.5309\n",
            "Epoch 2/4\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.1509 - accuracy: 0.9683\n",
            "Epoch 3/4\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0452 - accuracy: 0.9877\n",
            "Epoch 4/4\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0300 - accuracy: 0.9917\n",
            "1624/1624 [==============================] - 2s 1ms/step - loss: 0.0193 - accuracy: 0.9951\n",
            "122/122 [==============================] - 0s 1ms/step - loss: 0.0313 - accuracy: 0.9892\n",
            "MODEL:  12\n",
            "5194/5194 [==============================] - 12s 2ms/step - loss: 0.1778 - accuracy: 0.9422\n",
            "1624/1624 [==============================] - 2s 1ms/step - loss: 0.0180 - accuracy: 0.9939\n",
            "122/122 [==============================] - 0s 1ms/step - loss: 0.0305 - accuracy: 0.9900\n",
            "520/520 [==============================] - 3s 5ms/step - loss: 0.4502 - accuracy: 0.8780\n",
            "1624/1624 [==============================] - 2s 1ms/step - loss: 0.0188 - accuracy: 0.9936\n",
            "122/122 [==============================] - 0s 1ms/step - loss: 0.0343 - accuracy: 0.9890\n",
            "52/52 [==============================] - 2s 23ms/step - loss: 1.4726 - accuracy: 0.6551\n",
            "1624/1624 [==============================] - 2s 1ms/step - loss: 0.0633 - accuracy: 0.9835\n",
            "122/122 [==============================] - 0s 1ms/step - loss: 0.0688 - accuracy: 0.9810\n",
            "Epoch 1/2\n",
            "5194/5194 [==============================] - 13s 2ms/step - loss: 0.1830 - accuracy: 0.9431\n",
            "Epoch 2/2\n",
            "5194/5194 [==============================] - 12s 2ms/step - loss: 0.0229 - accuracy: 0.9922\n",
            "1624/1624 [==============================] - 2s 1ms/step - loss: 0.0095 - accuracy: 0.9970\n",
            "122/122 [==============================] - 0s 1ms/step - loss: 0.0210 - accuracy: 0.9941\n",
            "Epoch 1/2\n",
            "520/520 [==============================] - 3s 5ms/step - loss: 0.4712 - accuracy: 0.8933\n",
            "Epoch 2/2\n",
            "520/520 [==============================] - 2s 5ms/step - loss: 0.0206 - accuracy: 0.9931\n",
            "1624/1624 [==============================] - 2s 1ms/step - loss: 0.0174 - accuracy: 0.9939\n",
            "122/122 [==============================] - 0s 1ms/step - loss: 0.0359 - accuracy: 0.9861\n",
            "Epoch 1/2\n",
            "52/52 [==============================] - 2s 23ms/step - loss: 1.4246 - accuracy: 0.5933\n",
            "Epoch 2/2\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0515 - accuracy: 0.9854\n",
            "1624/1624 [==============================] - 2s 1ms/step - loss: 0.0213 - accuracy: 0.9944\n",
            "122/122 [==============================] - 0s 1ms/step - loss: 0.0327 - accuracy: 0.9877\n",
            "Epoch 1/3\n",
            "5194/5194 [==============================] - 13s 2ms/step - loss: 0.1738 - accuracy: 0.9474\n",
            "Epoch 2/3\n",
            "5194/5194 [==============================] - 13s 2ms/step - loss: 0.0205 - accuracy: 0.9927\n",
            "Epoch 3/3\n",
            "5194/5194 [==============================] - 12s 2ms/step - loss: 0.0121 - accuracy: 0.9959\n",
            "1624/1624 [==============================] - 2s 1ms/step - loss: 0.0062 - accuracy: 0.9982\n",
            "122/122 [==============================] - 0s 1ms/step - loss: 0.0362 - accuracy: 0.9915\n",
            "Epoch 1/3\n",
            "520/520 [==============================] - 3s 5ms/step - loss: 0.4580 - accuracy: 0.8790\n",
            "Epoch 2/3\n",
            "520/520 [==============================] - 2s 5ms/step - loss: 0.0183 - accuracy: 0.9943\n",
            "Epoch 3/3\n",
            "520/520 [==============================] - 2s 4ms/step - loss: 0.0121 - accuracy: 0.9961\n",
            "1624/1624 [==============================] - 2s 1ms/step - loss: 0.0082 - accuracy: 0.9972\n",
            "122/122 [==============================] - 0s 1ms/step - loss: 0.0235 - accuracy: 0.9933\n",
            "Epoch 1/3\n",
            "52/52 [==============================] - 2s 23ms/step - loss: 1.4815 - accuracy: 0.5889\n",
            "Epoch 2/3\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0482 - accuracy: 0.9866\n",
            "Epoch 3/3\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0233 - accuracy: 0.9928\n",
            "1624/1624 [==============================] - 2s 1ms/step - loss: 0.0146 - accuracy: 0.9964\n",
            "122/122 [==============================] - 0s 1ms/step - loss: 0.0279 - accuracy: 0.9910\n",
            "Epoch 1/4\n",
            "5194/5194 [==============================] - 12s 2ms/step - loss: 0.1789 - accuracy: 0.9418\n",
            "Epoch 2/4\n",
            "5194/5194 [==============================] - 12s 2ms/step - loss: 0.0212 - accuracy: 0.9935\n",
            "Epoch 3/4\n",
            "5194/5194 [==============================] - 12s 2ms/step - loss: 0.0143 - accuracy: 0.9957\n",
            "Epoch 4/4\n",
            "5194/5194 [==============================] - 12s 2ms/step - loss: 0.0091 - accuracy: 0.9969\n",
            "1624/1624 [==============================] - 2s 1ms/step - loss: 0.0178 - accuracy: 0.9946\n",
            "122/122 [==============================] - 0s 1ms/step - loss: 0.0628 - accuracy: 0.9851\n",
            "Epoch 1/4\n",
            "520/520 [==============================] - 3s 5ms/step - loss: 0.4480 - accuracy: 0.8815\n",
            "Epoch 2/4\n",
            "520/520 [==============================] - 2s 4ms/step - loss: 0.0219 - accuracy: 0.9924\n",
            "Epoch 3/4\n",
            "520/520 [==============================] - 2s 4ms/step - loss: 0.0126 - accuracy: 0.9964\n",
            "Epoch 4/4\n",
            "520/520 [==============================] - 2s 4ms/step - loss: 0.0114 - accuracy: 0.9964\n",
            "1624/1624 [==============================] - 2s 1ms/step - loss: 0.0098 - accuracy: 0.9968\n",
            "122/122 [==============================] - 0s 1ms/step - loss: 0.0304 - accuracy: 0.9902\n",
            "Epoch 1/4\n",
            "52/52 [==============================] - 2s 23ms/step - loss: 1.5023 - accuracy: 0.5715\n",
            "Epoch 2/4\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0526 - accuracy: 0.9862\n",
            "Epoch 3/4\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0249 - accuracy: 0.9928\n",
            "Epoch 4/4\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0179 - accuracy: 0.9950\n",
            "1624/1624 [==============================] - 2s 1ms/step - loss: 0.0124 - accuracy: 0.9967\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0288 - accuracy: 0.9905\n",
            "MODEL:  24\n",
            "5194/5194 [==============================] - 14s 3ms/step - loss: 0.1684 - accuracy: 0.9493\n",
            "1624/1624 [==============================] - 3s 2ms/step - loss: 0.0240 - accuracy: 0.9919\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 0.9887\n",
            "520/520 [==============================] - 3s 5ms/step - loss: 0.4319 - accuracy: 0.8782\n",
            "1624/1624 [==============================] - 3s 2ms/step - loss: 0.0141 - accuracy: 0.9957\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0324 - accuracy: 0.9892\n",
            "52/52 [==============================] - 2s 29ms/step - loss: 1.4252 - accuracy: 0.6383\n",
            "1624/1624 [==============================] - 3s 2ms/step - loss: 0.0460 - accuracy: 0.9874\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0522 - accuracy: 0.9843\n",
            "Epoch 1/2\n",
            "5194/5194 [==============================] - 14s 3ms/step - loss: 0.1702 - accuracy: 0.9460\n",
            "Epoch 2/2\n",
            "5194/5194 [==============================] - 13s 3ms/step - loss: 0.0235 - accuracy: 0.9917\n",
            "1624/1624 [==============================] - 3s 2ms/step - loss: 0.0094 - accuracy: 0.9969\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0304 - accuracy: 0.9905\n",
            "Epoch 1/2\n",
            "520/520 [==============================] - 3s 5ms/step - loss: 0.4419 - accuracy: 0.8699\n",
            "Epoch 2/2\n",
            "520/520 [==============================] - 3s 5ms/step - loss: 0.0188 - accuracy: 0.9941\n",
            "1624/1624 [==============================] - 3s 2ms/step - loss: 0.0092 - accuracy: 0.9974\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0224 - accuracy: 0.9926\n",
            "Epoch 1/2\n",
            "52/52 [==============================] - 2s 29ms/step - loss: 1.3721 - accuracy: 0.6476\n",
            "Epoch 2/2\n",
            "52/52 [==============================] - 1s 29ms/step - loss: 0.0374 - accuracy: 0.9886\n",
            "1624/1624 [==============================] - 3s 2ms/step - loss: 0.0186 - accuracy: 0.9951\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0318 - accuracy: 0.9884\n",
            "Epoch 1/3\n",
            "5194/5194 [==============================] - 14s 3ms/step - loss: 0.1664 - accuracy: 0.9424\n",
            "Epoch 2/3\n",
            "5194/5194 [==============================] - 14s 3ms/step - loss: 0.0241 - accuracy: 0.9922\n",
            "Epoch 3/3\n",
            "5194/5194 [==============================] - 14s 3ms/step - loss: 0.0130 - accuracy: 0.9960\n",
            "1624/1624 [==============================] - 3s 2ms/step - loss: 0.0118 - accuracy: 0.9973\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0483 - accuracy: 0.9887\n",
            "Epoch 1/3\n",
            "520/520 [==============================] - 3s 5ms/step - loss: 0.4193 - accuracy: 0.8857\n",
            "Epoch 2/3\n",
            "520/520 [==============================] - 3s 5ms/step - loss: 0.0161 - accuracy: 0.9948\n",
            "Epoch 3/3\n",
            "520/520 [==============================] - 3s 5ms/step - loss: 0.0136 - accuracy: 0.9955\n",
            "1624/1624 [==============================] - 3s 2ms/step - loss: 0.0113 - accuracy: 0.9958\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0270 - accuracy: 0.9918\n",
            "Epoch 1/3\n",
            "52/52 [==============================] - 2s 29ms/step - loss: 1.3840 - accuracy: 0.5827\n",
            "Epoch 2/3\n",
            "52/52 [==============================] - 2s 29ms/step - loss: 0.0400 - accuracy: 0.9870\n",
            "Epoch 3/3\n",
            "52/52 [==============================] - 2s 29ms/step - loss: 0.0215 - accuracy: 0.9934\n",
            "1624/1624 [==============================] - 3s 2ms/step - loss: 0.0143 - accuracy: 0.9963\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0292 - accuracy: 0.9892\n",
            "Epoch 1/4\n",
            "5194/5194 [==============================] - 14s 3ms/step - loss: 0.1715 - accuracy: 0.9459\n",
            "Epoch 2/4\n",
            "5194/5194 [==============================] - 14s 3ms/step - loss: 0.0223 - accuracy: 0.9934\n",
            "Epoch 3/4\n",
            "5194/5194 [==============================] - 14s 3ms/step - loss: 0.0139 - accuracy: 0.9953\n",
            "Epoch 4/4\n",
            "5194/5194 [==============================] - 14s 3ms/step - loss: 0.0102 - accuracy: 0.9970\n",
            "1624/1624 [==============================] - 3s 2ms/step - loss: 0.0044 - accuracy: 0.9988\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0349 - accuracy: 0.9926\n",
            "Epoch 1/4\n",
            "520/520 [==============================] - 3s 5ms/step - loss: 0.4244 - accuracy: 0.8855\n",
            "Epoch 2/4\n",
            "520/520 [==============================] - 3s 5ms/step - loss: 0.0185 - accuracy: 0.9936\n",
            "Epoch 3/4\n",
            "520/520 [==============================] - 3s 5ms/step - loss: 0.0128 - accuracy: 0.9956\n",
            "Epoch 4/4\n",
            "520/520 [==============================] - 3s 5ms/step - loss: 0.0092 - accuracy: 0.9971\n",
            "1624/1624 [==============================] - 3s 2ms/step - loss: 0.0111 - accuracy: 0.9958\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0350 - accuracy: 0.9872\n",
            "Epoch 1/4\n",
            "52/52 [==============================] - 2s 29ms/step - loss: 1.4277 - accuracy: 0.5960\n",
            "Epoch 2/4\n",
            "52/52 [==============================] - 2s 29ms/step - loss: 0.0417 - accuracy: 0.9875\n",
            "Epoch 3/4\n",
            "52/52 [==============================] - 1s 29ms/step - loss: 0.0220 - accuracy: 0.9934\n",
            "Epoch 4/4\n",
            "52/52 [==============================] - 2s 29ms/step - loss: 0.0165 - accuracy: 0.9954\n",
            "1624/1624 [==============================] - 3s 2ms/step - loss: 0.0107 - accuracy: 0.9974\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0288 - accuracy: 0.9905\n",
            "MODEL:  36\n",
            "5194/5194 [==============================] - 27s 5ms/step - loss: 0.1511 - accuracy: 0.9480\n",
            "1624/1624 [==============================] - 4s 3ms/step - loss: 0.0188 - accuracy: 0.9939\n",
            "122/122 [==============================] - 0s 3ms/step - loss: 0.0389 - accuracy: 0.9882\n",
            "520/520 [==============================] - 6s 10ms/step - loss: 0.3232 - accuracy: 0.8957\n",
            "1624/1624 [==============================] - 4s 3ms/step - loss: 0.0206 - accuracy: 0.9929\n",
            "122/122 [==============================] - 0s 3ms/step - loss: 0.0376 - accuracy: 0.9872\n",
            "52/52 [==============================] - 4s 60ms/step - loss: 1.1046 - accuracy: 0.7215\n",
            "1624/1624 [==============================] - 4s 2ms/step - loss: 0.0244 - accuracy: 0.9921\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0385 - accuracy: 0.9859\n",
            "Epoch 1/2\n",
            "5194/5194 [==============================] - 25s 5ms/step - loss: 0.1502 - accuracy: 0.9491\n",
            "Epoch 2/2\n",
            "5194/5194 [==============================] - 25s 5ms/step - loss: 0.0247 - accuracy: 0.9927\n",
            "1624/1624 [==============================] - 4s 2ms/step - loss: 0.0151 - accuracy: 0.9963\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 0.9884\n",
            "Epoch 1/2\n",
            "520/520 [==============================] - 6s 11ms/step - loss: 0.3257 - accuracy: 0.8968\n",
            "Epoch 2/2\n",
            "520/520 [==============================] - 6s 11ms/step - loss: 0.0192 - accuracy: 0.9932\n",
            "1624/1624 [==============================] - 4s 3ms/step - loss: 0.0098 - accuracy: 0.9967\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0279 - accuracy: 0.9887\n",
            "Epoch 1/2\n",
            "52/52 [==============================] - 4s 61ms/step - loss: 1.1256 - accuracy: 0.7687\n",
            "Epoch 2/2\n",
            "52/52 [==============================] - 3s 61ms/step - loss: 0.0244 - accuracy: 0.9918\n",
            "1624/1624 [==============================] - 4s 3ms/step - loss: 0.0127 - accuracy: 0.9964\n",
            "122/122 [==============================] - 0s 3ms/step - loss: 0.0278 - accuracy: 0.9897\n",
            "Epoch 1/3\n",
            "5194/5194 [==============================] - 28s 5ms/step - loss: 0.1559 - accuracy: 0.9428\n",
            "Epoch 2/3\n",
            "5194/5194 [==============================] - 28s 5ms/step - loss: 0.0235 - accuracy: 0.9927\n",
            "Epoch 3/3\n",
            "5194/5194 [==============================] - 28s 5ms/step - loss: 0.0141 - accuracy: 0.9957\n",
            "1624/1624 [==============================] - 5s 3ms/step - loss: 0.0081 - accuracy: 0.9978\n",
            "122/122 [==============================] - 0s 3ms/step - loss: 0.0354 - accuracy: 0.9918\n",
            "Epoch 1/3\n",
            "520/520 [==============================] - 6s 11ms/step - loss: 0.3225 - accuracy: 0.8950\n",
            "Epoch 2/3\n",
            "520/520 [==============================] - 6s 11ms/step - loss: 0.0203 - accuracy: 0.9933\n",
            "Epoch 3/3\n",
            "520/520 [==============================] - 6s 11ms/step - loss: 0.0107 - accuracy: 0.9966\n",
            "1624/1624 [==============================] - 4s 3ms/step - loss: 0.0067 - accuracy: 0.9982\n",
            "122/122 [==============================] - 0s 3ms/step - loss: 0.0292 - accuracy: 0.9902\n",
            "Epoch 1/3\n",
            "52/52 [==============================] - 4s 61ms/step - loss: 1.0881 - accuracy: 0.7151\n",
            "Epoch 2/3\n",
            "52/52 [==============================] - 3s 60ms/step - loss: 0.0226 - accuracy: 0.9930\n",
            "Epoch 3/3\n",
            "52/52 [==============================] - 3s 60ms/step - loss: 0.0167 - accuracy: 0.9946\n",
            "1624/1624 [==============================] - 4s 2ms/step - loss: 0.0091 - accuracy: 0.9974\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0256 - accuracy: 0.9926\n",
            "Epoch 1/4\n",
            "5194/5194 [==============================] - 25s 5ms/step - loss: 0.1529 - accuracy: 0.9473\n",
            "Epoch 2/4\n",
            "5194/5194 [==============================] - 25s 5ms/step - loss: 0.0241 - accuracy: 0.9930\n",
            "Epoch 3/4\n",
            "5194/5194 [==============================] - 25s 5ms/step - loss: 0.0166 - accuracy: 0.9951\n",
            "Epoch 4/4\n",
            "5194/5194 [==============================] - 25s 5ms/step - loss: 0.0090 - accuracy: 0.9973\n",
            "1624/1624 [==============================] - 4s 2ms/step - loss: 0.0228 - accuracy: 0.9954\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0691 - accuracy: 0.9864\n",
            "Epoch 1/4\n",
            "520/520 [==============================] - 6s 11ms/step - loss: 0.3208 - accuracy: 0.9055\n",
            "Epoch 2/4\n",
            "520/520 [==============================] - 5s 10ms/step - loss: 0.0172 - accuracy: 0.9936\n",
            "Epoch 3/4\n",
            "520/520 [==============================] - 5s 11ms/step - loss: 0.0127 - accuracy: 0.9959\n",
            "Epoch 4/4\n",
            "520/520 [==============================] - 5s 11ms/step - loss: 0.0099 - accuracy: 0.9967\n",
            "1624/1624 [==============================] - 4s 2ms/step - loss: 0.0060 - accuracy: 0.9981\n",
            "122/122 [==============================] - 0s 3ms/step - loss: 0.0254 - accuracy: 0.9918\n",
            "Epoch 1/4\n",
            "52/52 [==============================] - 4s 60ms/step - loss: 1.1222 - accuracy: 0.6949\n",
            "Epoch 2/4\n",
            "52/52 [==============================] - 3s 61ms/step - loss: 0.0263 - accuracy: 0.9912\n",
            "Epoch 3/4\n",
            "52/52 [==============================] - 3s 61ms/step - loss: 0.0141 - accuracy: 0.9956\n",
            "Epoch 4/4\n",
            "52/52 [==============================] - 3s 61ms/step - loss: 0.0107 - accuracy: 0.9966\n",
            "1624/1624 [==============================] - 4s 2ms/step - loss: 0.0087 - accuracy: 0.9975\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0287 - accuracy: 0.9902\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ns0xjrTFjZU5",
        "outputId": "def600f3-7c66-4153-8dee-1e2a2b561b9b"
      },
      "source": [
        "print(results_final[results_final.valid == results_final.valid.max()])\n",
        "print(results_final[results_final.valid>99.2])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    model            nodes  epochs  batch_size  train  valid\n",
            "15     15  [200, 200, 100]       2          10   99.7  99.41\n",
            "    model            nodes  epochs  batch_size  train  valid\n",
            "6       6   [100, 100, 50]       3          10  99.78  99.23\n",
            "15     15  [200, 200, 100]       2          10  99.70  99.41\n",
            "19     19  [200, 200, 100]       3         100  99.72  99.33\n",
            "28     28  [300, 200, 100]       2         100  99.74  99.26\n",
            "33     33  [300, 200, 100]       4          10  99.88  99.26\n",
            "44     44  [500, 500, 250]       3        1000  99.74  99.26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLSJLmrWIDVK",
        "outputId": "4330de3a-0156-4a30-dd6b-79439758b703"
      },
      "source": [
        "#Final Model\n",
        "model = Sequential()\n",
        "model.add(Dense(200, input_dim=input_dim, activation='relu'))\n",
        "model.add(Dense(200, activation='relu'))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(8, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, Y_train, epochs=2, batch_size=100)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "520/520 [==============================] - 3s 4ms/step - loss: 0.4567 - accuracy: 0.8713\n",
            "Epoch 2/2\n",
            "520/520 [==============================] - 2s 4ms/step - loss: 0.0191 - accuracy: 0.9939\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f07bc76af98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-qlEaE3IkyP",
        "outputId": "fa9670b4-c435-4d59-c57d-0b2fa26c83ee"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "predicted = model.predict_classes(X_test)\n",
        "Y_pred = encoder.inverse_transform(predicted)\n",
        "Y_test = test_features['lang']\n",
        "accuracy = accuracy_score(Y_test,Y_pred)\n",
        "print(accuracy)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.993180068199318\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIVy32W-aZcq"
      },
      "source": [
        "Accuracy of best performing ANN model : 99.31 %"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oj8VBUbCak4m"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}